<!DOCTYPE HTML>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

        <title>David Bauer</title>

        <meta name="author" content="David Bauer">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" type="text/css" href="stylesheet.css">

    </head>

    <body>
        <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:0px">
                    <td style="padding:0px">
                        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                <tr style="padding:0px">
                                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                                        <p class="name" style="text-align: center;">David Bauer</p>
                                        <p>
                                        I am research scientist at <a target="_blank" href="https://www.meta.com/">Meta</a>. Before that, I built systems that leverage deep learning to enable scientific data visualization. My work focuses on the development of high-performance neural rendering systems and virtual reality (VR) visualization applications. I did my PhD at UC Davis where I was advised by <a target="_blank" href="https://web.cs.ucdavis.edu/~ma/">Kwan-Liu Ma</a> as part of the <a target="_blank" href="https://vidi.cs.ucdavis.edu/">VIDi</a> group. During that time, I interned at <a target="_blank" href="https://studios.disneyresearch.com/">Disney Research Studios</a> where I worked on neural path guiding and at <a target="_blank" href="https://www.intel.com/content/www/us/en/developer/topic-technology/graphics-research/researchers.html">Intel</a>, working on feature extensions to <a target="_blank" href="https://www.openimagedenoise.org/">Open Image Denoise</a>. My bachelors is from the Vienna University of Technology where I completed my thesis jointly at <a target="_blank" href="https://www.imagebiopsy.com/">ImageBiopsy Lab</a> advised by <a target="_blank" href="https://www.cg.tuwien.ac.at/staff/EduardGr%C3%B6ller">Eduard Gröller</a>. 
                                        </p>
                                        <p style="text-align:center">
                                        <a target="_blank" href="mailto:david.bauer009@gmail.com">Email</a> &nbsp;/&nbsp;
                                        <a target="_blank" href="data/DavidBauer-Resume.pdf">Resume</a> &nbsp;/&nbsp;
                                        <a target="_blank" href="data/DavidBauer-CV.pdf">CV</a> &nbsp;/&nbsp;
                                        <a target="_blank" href="https://scholar.google.com/citations?user=CXwgxpsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                                        <a target="_blank" href="https://github.com/DBauer15/">Github</a> &nbsp;/&nbsp;
                                        <a target="_blank" href="https://www.linkedin.com/in/dbauer15/">LinkedIn</a>
                                        </p>
                                    </td>
                                    <td style="padding:2.5%;width:37%;max-width:37%">
                                        <a href="images/DavidBauer.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/DavidBauer.jpg" class="hoverZoomLink"></a>
                                    </td>
                                </tr>
                            </tbody></table>

                            <!-- RESEARCH SECTION -->
                            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                    <tr>
                                        <td style="padding:16px;width:100%;vertical-align:middle">
                                            <h2>Research</h2>
                                            <p></p>
                                        </td>
                                    </tr>
                                </tbody>
                            </table>
                            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/gscache.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://dbauer15.github.io/papers/gscache/">
                                            <span class="papertitle">GSCache: Real-Time Radiance Caching for Volume Path Tracing using 3D Gaussian Splatting</span>
                                        </a>
                                        <br>
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <a href="">Hamid Gadirov</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2026
                                        <br>
                                        <a target="_blank" href="https://dbauer15.github.io/papers/gscache/">project page</a>
                                        /
                                        <a target="_blank" href="https://www.arxiv.org/abs/2507.19718">arxiv</a>
                                        <p></p>
                                        <p>
                                        A path-space radiance caching method for real-time volume path tracing. The method uses 3D Gaussian splatting to create a multi-level, trainable cache. The approach reduces noise and improves image quality without increasing rendering costs. The cache dynamically adapts to changes in lighting and transfer functions. It outperforms state-of-the-art neural radiance caching in both quality and efficiency.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/hyperflint.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.70134">
                                            <span class="papertitle">HyperFLINT: Hypernetwork‐based Flow Estimation and Temporal Interpolation for Scientific Ensemble Visualization</span>
                                        </a>
                                        <br>
                                        <a href="">Hamid Gadirov</a>,&nbsp;
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>,&nbsp;
                                        <a href="">Jos Roerdink</a>,&nbsp;
                                        <a href="">Steffen Frey</a>
                                        <br>
                                        <em>Computer Graphics Forum (CGF)</em>, 2025
                                        <br>
                                        <a target="_blank" href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.70134">paper</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2412.04095">arxiv</a>
                                        <p></p>
                                        <p>
                                        A deep learning framework for estimating flow fields, temporally interpolating scalar fields, and exploring parameter spaces in spatio-temporal scientific ensemble data. By using a hypernetwork to incorporate simulation parameters, it dynamically adapts to diverse conditions.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/cinr.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://diglib.eg.org/items/d04e0485-4347-4ea5-9950-aa9a6967a732">
                                            <span class="papertitle">From Cluster to Desktop: A Cache-Accelerated INR framework for Interactive Visualization of Tera-Scale Data</span>
                                        </a>
                                        <br>
                                        <a href="">Daniel Zavorotny</a>,&nbsp;
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>Eurographics Symposium on Parallel Graphics and Visualization (EGPGV)</em>, 2025
                                        <br>
                                        <a target="_blank" href="https://diglib.eg.org/items/d04e0485-4347-4ea5-9950-aa9a6967a732">paper</a>
                                        /
                                        <a target="_blank" href="https://github.com/VIDILabs/cINR">code</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2504.18001">arxiv</a>
                                        <p></p>
                                        <p>
                                        A GPU-accelerated framework that enables fast, interactive visualization of implicit neural representations (INRs) for massive scientific datasets. It uses a scalable, multi-resolution cache to minimize redundant inference steps to achieve a 5× speedup over state-of-the-art INR rendering. This allows tera-scale datasets to be explored on consumer-grade hardware after in situ compression on high-performance systems.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/im_networks.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10765388">
                                            <span class="papertitle">A Multi-Layout Design For Immersive Visualization of Hierarchical Network Data</span>
                                        </a>
                                        <br>
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Chengbo Zheng</a>,&nbsp;
                                        <a href="">Oh-Hyun Kwon</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>, 2024
                                        <br>
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10765388">paper</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2112.10272">arxiv</a>
                                        <p></p>
                                        <p>
                                        A multi-layout design for immersive exploration of hierarchical network data in VR. The design offers four distinct views to optimally utilize available space and adapt to different tasks. A user study shows our approach outperforms traditional single-layout methods in both focused and whole-network scenarios.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/photonfields.jpg' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10297590">
                                            <span class="papertitle">Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination</span>
                                        </a>
                                        <br>
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2024
                                        <br>
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10297590">paper</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2304.07338">arxiv</a>
                                        <p></p>
                                        <p>
                                        A neural representation for real-time, phase-function-aware volumetric global illumination. Trained in seconds on multi-phase photon caches, they enable interactive path-traced rendering of large datasets with reduced noise and faster performance than traditional methods. Our custom neural path tracer demonstrates high visual quality and accuracy while maintaining interactive framerates.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/inr.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://ieeexplore.ieee.org/document/10175377">
                                            <span class="papertitle">Interactive Volume Visualization via Multi-Resolution Hash Encoding Based Neural Representation</span>
                                        </a>
                                        <br>
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Michael Doyle</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2024
                                        <br>
                                        <a target="_blank" href="https://ieeexplore.ieee.org/document/10175377">paper</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2207.11620">arxiv</a>
                                        /
                                        <a target="_blank" href="https://github.com/VIDILabs/instantvnr">code</a>
                                        <p></p>
                                        <p>
                                        An implicit neural representation (INR) for large-scale volume data compression. The approach achieves high fidelity reconstruction with up to 1000× data compression rates, supports terascale datasets on a single RTX 3090, and eliminates pre-training by fitting training into the rendering loop. It outperforms state-of-the-art methods in speed, quality, and scalability.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/hyperinr.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://arxiv.org/abs/2304.04188">
                                            <span class="papertitle">HyperINR: A Fast and Predictive Hypernetwork for Implicit Neural Representations via Knowledge Distillation</span>
                                        </a>
                                        <br>
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Yuyang Chen</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>preprint</em>, 2023
                                        <br>
                                        <a target="_blank" href="https://arxiv.org/abs/2304.04188">arxiv</a>
                                        <p></p>
                                        <p>
                                        A hypernetwork technique that generates weights for a compact implicit neural representation (INR) for scientific visualization. It combines multiresolution hash encodings with knowledge distillation to achieve high quality reconstruction while supporting tasks like temporal super-resolution and dynamic lighting.</p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/fovolnet.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9903564">
                                            <span class="papertitle">FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks</span>
                                        </a>
                                        <br>
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Qi Wu</a>,&nbsp;
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks</em>, 2023
                                        <br>
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9903564">paper</a>
                                        /
                                        <a target="_blank" href="https://arxiv.org/abs/2209.09965">arxiv</a>
                                        <p></p>
                                        <p>
                                        A neural reconstruction method for sparse foveated rendering achieving high-quality, interactive results for volume visualization. By sparsely sampling around the user's focal point and reconstructing the frame with a compact neural network, it saves computation time while maintaining perceptual quality. FoVolNet outperforms state-of-the-art neural reconstruction techniques in both speed and visual fidelity.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/im_fatigue.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9583829">
                                            <span class="papertitle">A Comparison of the Fatigue Progression of Eye-Tracked and Motion-Controlled Interaction in Immersive Space</span>
                                        </a>
                                        <br>
                                        <a href="">Lukas Masopust</a>,&nbsp;
                                        <strong>David Bauer</strong>,&nbsp;
                                        <a href="">Siyuan Yao</a>
                                        <a href="">Kwan-Liu Ma</a>
                                        <br>
                                        <em>EEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>, 2021
                                        <br>
                                        <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9583829">paper</a>
                                        <p></p>
                                        <p>
                                        A comparison of eye-tracking-based interaction with traditional motion controller-based interaction in VR, focusing on how fatigue affects performance during prolonged use. The study reveals fatigue patterns for each method, offering new insights for designing future XR interaction techniques.
                                        </p>
                                    </td>
                                </tr>
                            </table>
                            <!-- RESEARCH SECTION END -->

                            <!-- PROJECTS SECTION -->
                            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                    <tr>
                                        <td style="padding:16px;width:100%;vertical-align:middle">
                                            <h2>Projects</h2>
                                            <p></p>
                                        </td>
                                    </tr>
                                </tbody>
                            </table>
                            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/stage.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:16px;width:80%;vertical-align:top">
                                        <a target="_blank" href="https://github.com/DBauer15/stage">
                                            <span class="papertitle">Stage: A universal 3D Scene Loader</span>
                                        </a>
                                        <br>
                                        <p>
                                        Stage is a tool that lets you load various 3D scene and object formats into a uniform representation that is easy to use and integrate into your renderer, ray tracing application or game engine.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/fabrt.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:16px;width:80%;vertical-align:top">
                                        <a target="_blank" href="https://github.com/DBauer15/FaRT">
                                            <span class="papertitle">FaRT: Fabulous Ray Tracer</span>
                                        </a>
                                        <br>
                                        <p>
                                        Hobby project that implements real-time path tracing for various backends to facilitate learning of different graphics APIs and experiment with various rendering techniques like reservor sampling.
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <div class="one">
                                            <img src='images/ovr.png' width=100%>
                                        </div>
                                    </td>
                                    <td style="padding:16px;width:80%;vertical-align:top">
                                        <a target="_blank" href="https://github.com/VIDILabs/open-volume-renderer">
                                            <span class="papertitle">OVR: Open Volume Renderer</span>
                                        </a>
                                        <br>
                                        <p>
                                        Scientific visualization renderer developed in our research group at UC Davis. Supports various types of volume rendering and different rendering backends like NVIDIA Optix or Intel OSPRay. It forms the basis for a lot of our research work.
                                        </p>
                                    </td>
                                </tr>
                            </table>
                            <!-- PROJECTS SECTION END -->

                            <!-- PAGE CREDITS SECTION -->
                            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                                <tbody>
                                    <tr>
                                        <td style="padding:0px">
                                            <br>
                                            <p style="text-align:right;font-size:small;">
                                            Website template can be found <a target="_blank" href="https://github.com/jonbarron/jonbarron_website">here</a>. Credits to <a target="_blank" href="http://jonbarron.info/">Jonathan Barron</a>.
                                            </p>
                                        </td>
                                    </tr>
                                </tbody>
                            </table>
                            <!-- PAGE CREDITS SECTION END -->
                    </td>
                </tr>
        </table>
    </body>
</html>
